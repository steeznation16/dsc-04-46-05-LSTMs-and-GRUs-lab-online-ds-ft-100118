{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMs and GRUs - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll learn how to use LSTM cells and GRU cells to build **_Recurrent Neural Networks_** to work with text data!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Explain the the problem of vanishing and exploding gradients, and why they are a problem when training RNNs\n",
    "* Demonstrate an understanding of the basic architecture and function of a Long Short Term Memory cell\n",
    "* Demonstrate an understanding of the basic architecture and function of a Gated Recurrent Unit\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "In this lab, we'll see a basic example of how we can use LSTMs and GRU cells to build a Recurrent Neural Network for text classification on the _Newsgroups Dataset_ that is included with scikit-learn. The goal of this lab build 2 nearly identical models so that we can benchmark performances for both LSTMs and GRUs and compare them against one another. \n",
    "\n",
    "We'll begin by loading in everything we'll need for this lab. \n",
    "\n",
    "In the cell below, import the following items:\n",
    "\n",
    "* `fetch20_newsgroups`, from `sklearn.datasets`\n",
    "* `keras`\n",
    "* from `keras.layers`, import the following layers:\n",
    "    * `LSTM`\n",
    "    * `GRU`\n",
    "    * `Dense`\n",
    "    * `GlobalMaxPool1D`\n",
    "    * `Embedding`\n",
    "    * `Dropout`\n",
    "* `Sequential`, from `keras.models`\n",
    "* `text` and `sequence`, from `keras.preprocessing`\n",
    "* `numpy`, `matplotlib`, and `pandas`. Set the standard alias for each.\n",
    "* Also set matplotlib visualizations to appear inline, and use numpy to set a random seed of `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import keras\n",
    "from keras.layers import LSTM, GRU, Dense, GlobalMaxPool1D, Embedding, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text, sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Preprocessing Our Text Data\n",
    "\n",
    "Since we'll be working with a text dataset, we'll need to do a few things to get it into a format where our LSTM and GRU networks can work with it. Specifically, we'll need to:\n",
    "\n",
    "* Import and load the data and labels, and store them separately\n",
    "* Convert the labels to a one-hot encoded format\n",
    "* tokenize our text data\n",
    "* Convert the tokenized text to sequences\n",
    "* Pad the sequences, so that they are all the same length. \n",
    "\n",
    "Let's start by loading in our data. In the cell below, call `fetch_20newsgroups()` to get our data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split off our data and labels, which are currently stored in our `newgroups` object's `.data` and `.target` attributes, respectively.  \n",
    "\n",
    "In the cell below, store the `data` and the `target` in the appropriate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newsgroups.data\n",
    "labels = newsgroups.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll need to convert our data to a one-hot encoded format. Keras has a utility function that can easily do this for us called `to_categorical()`, which can be found in `keras.utils`.\n",
    "\n",
    "In the cell below, call the `to_categorical()` function and pass in `labels`, as well as the number of unique classes in our labels, which is `20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = keras.utils.to_categorical(labels, num_classes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sequences From Text\n",
    "\n",
    "By now, you've seen this code before. Anytime we work with text data for deep learning, you can expect to see the following preprocessing pattern:\n",
    "\n",
    "> **raw text --> tokenized text --> text sequences --> padded sequences**\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Instantiate a `Tokenizer` object, which can be found in the `text` module that we've already imported from `keras`. Set the `num_words` parameter to `20000`, so that our model only keeps the 20,000 must used words.\n",
    "* Call the `tokenizer` object's `.fit_on_texts()` method, and pass in our `data`, which should be converted to a python `list` (do this right inside the method call)\n",
    "* Next, call the `tokenizer` object's `texts_to_sequences()` method and pass in our `data`.\n",
    "* Finally, use the `sequence` module's `pad_sequences()` method to make sure all of our sequences are padded to the exact same size, so that we can set hard limits on the dimensionality of our inputs. For input, pass in our `list_tokenized_train`, as well as the parameter `maxlen=100`, so that all sequences are padded to be of length 100, regardless of the amount of text they actually contain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(list(data))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(data)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We've now finished preprocessing our data, and we're ready to build, compile, and train our models!\n",
    "\n",
    "## Creating Our Models\n",
    "\n",
    "Now, to the fun part--creating, and training to similar LSTM and GRU networks, and comparing their performance and runtimes. \n",
    "\n",
    "### Architectures\n",
    "\n",
    "Both of our models will stick to the following architecture:\n",
    "\n",
    "1. An `Embedding()` layer, of size `(20000, 128)`. This means that the first parameter passed into the embedding layer should be `20000` for the 20,000 words in our our text vocabulary, and the second parameter should be `128`, for the size of the Dense vectors the embedding layer will learn for each of the 20,000 words. \n",
    "2. An `LSTM()` layer (or `GRU()` layer, for the second model) of size `50`. During this step, also set the `return_sequences` parameter to `True`, so that during back propagation our models will calculate loss and learn for every step of the sequence, not just the final result of the sequence.\n",
    "3. A `GlobalMaxPool1D()` layer, so that our model performs a combined _MaxPool_  operation across all weights in the recurrent layer. \n",
    "4. A `Dropout()` layer set to `0.5`.\n",
    "5. A `Dense()` layer of size `50`, with this layer's `activation` parameter set to `'relu'`\n",
    "6. Another `Dropout()` layer set to `0.5`\n",
    "7. A `Dense()` layer that will act as our output layer. This layer should contain `20` neurons (one for each possible predicted class), and should have it's `activation` parameter set to `'softmax'`\n",
    "\n",
    "In the cell below, create our `LSTM` model. \n",
    "\n",
    "**_NOTE:_** For simplicity's sake, we recommend you make use a `Sequential()` object and use that object's `.add()` parameter to add each layer to the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/steeznation/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/steeznation/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(20000, 128))\n",
    "lstm_model.add(LSTM(50, return_sequences=True))\n",
    "lstm_model.add(GlobalMaxPool1D())\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(50, activation='relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation Parameters\n",
    "\n",
    "Now that we've built our model, we still need to compile it. \n",
    "\n",
    "In the cell below, call our model's `.compile()` method and pass in the following parameters:\n",
    "\n",
    "* `loss='categorical_crossentropy'`\n",
    "* `optimizer='adam'`\n",
    "* `metrics=['accuracy']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Our Compiled Model\n",
    "\n",
    "Before we train our model, let's take a look at what it looks like, and see how many trainable parameters it has. In the cell below, call our model's `.summary()` method to inspect it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 50)          35800     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "=================================================================\n",
      "Total params: 2,599,370\n",
      "Trainable params: 2,599,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just under 2.6 million trainable parameters--that's a pretty decent-sized model!\n",
    "\n",
    "### Training Our Model\n",
    "\n",
    "Now that we have preprocessed our data, created our model, and compiled it, we're ready for the moment of truth--training!\n",
    "\n",
    "In the cell below, call our model's `.train()` method and pass in the following parameters:\n",
    "\n",
    "* `X_t`, our padded sequence data\n",
    "* `labels`\n",
    "* `epochs=2`\n",
    "* `batch_size=32`, so that our model trains on mini-batches of 32 examples at a time.\n",
    "* `validation_data=0.1`, so that our model hold out 10% of our data for validation.\n",
    "\n",
    "**_NOTE:_** This will take a few minutes per epoch to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyternotify\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/e9/11cb4861003a3a79a8a7a107cc9ee3983be9938989436bd3c8280c26d86f/jupyternotify-0.1.15.tar.gz\n",
      "Requirement already satisfied: ipython in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyternotify) (7.2.0)\n",
      "Requirement already satisfied: jupyter in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyternotify) (1.0.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (4.3.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (4.6.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (0.13.2)\n",
      "Requirement already satisfied: backcall in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (0.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (40.6.3)\n",
      "Requirement already satisfied: decorator in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (4.3.0)\n",
      "Requirement already satisfied: pickleshare in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (0.7.5)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (0.1.0)\n",
      "Requirement already satisfied: pygments in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (2.3.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipython->jupyternotify) (2.0.7)\n",
      "Requirement already satisfied: jupyter-console in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyter->jupyternotify) (6.0.0)\n",
      "Requirement already satisfied: qtconsole in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyter->jupyternotify) (4.4.3)\n",
      "Requirement already satisfied: ipykernel in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyter->jupyternotify) (5.1.0)\n",
      "Requirement already satisfied: nbconvert in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyter->jupyternotify) (5.4.0)\n",
      "Requirement already satisfied: notebook in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyter->jupyternotify) (5.7.4)\n",
      "Requirement already satisfied: ipywidgets in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyter->jupyternotify) (7.4.2)\n",
      "Requirement already satisfied: six in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->ipython->jupyternotify) (1.12.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->ipython->jupyternotify) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython->jupyternotify) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython->jupyternotify) (0.3.1)\n",
      "Requirement already satisfied: wcwidth in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->jupyternotify) (0.1.7)\n",
      "Requirement already satisfied: jupyter_client in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyter-console->jupyter->jupyternotify) (5.2.4)\n",
      "Requirement already satisfied: jupyter_core in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from qtconsole->jupyter->jupyternotify) (4.4.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipykernel->jupyter->jupyternotify) (5.1.1)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->jupyternotify) (0.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->jupyternotify) (2.10)\n",
      "Requirement already satisfied: nbformat>=4.4 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->jupyternotify) (4.4.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->jupyternotify) (0.2.3)\n",
      "Requirement already satisfied: bleach in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->jupyternotify) (3.0.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->jupyternotify) (1.4.2)\n",
      "Requirement already satisfied: testpath in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->jupyternotify) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->jupyternotify) (0.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->jupyternotify) (17.1.2)\n",
      "Requirement already satisfied: prometheus-client in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->jupyternotify) (0.5.0)\n",
      "Requirement already satisfied: Send2Trash in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->jupyternotify) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from notebook->jupyter->jupyternotify) (0.8.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from ipywidgets->jupyter->jupyternotify) (3.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jupyter_client->jupyter-console->jupyter->jupyternotify) (2.7.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from jinja2->nbconvert->jupyter->jupyternotify) (1.1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert->jupyter->jupyternotify) (2.6.0)\n",
      "Requirement already satisfied: webencodings in /Users/steeznation/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->jupyter->jupyternotify) (0.5.1)\n",
      "Building wheels for collected packages: jupyternotify\n",
      "  Running setup.py bdist_wheel for jupyternotify ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/steeznation/Library/Caches/pip/wheels/20/1d/73/93a18756ec3f9425e7597cc42d93ef9d355c65ac40f4fcd123\n",
      "Successfully built jupyternotify\n",
      "Installing collected packages: jupyternotify\n",
      "Successfully installed jupyternotify-0.1.15\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install jupyternotify\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "## Run %%notify to create notification for completed cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/steeznation/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/steeznation/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/2\n",
      "10182/10182 [==============================] - 39s 4ms/step - loss: 2.9095 - acc: 0.0848 - val_loss: 2.5752 - val_acc: 0.1758\n",
      "Epoch 2/2\n",
      "10182/10182 [==============================] - 38s 4ms/step - loss: 2.3595 - acc: 0.2204 - val_loss: 1.8257 - val_acc: 0.4920\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"e0bd6665-3784-4d94-9e02-6a6e0cf0440c\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"e0bd6665-3784-4d94-9e02-6a6e0cf0440c\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_model.fit(X_t, labels, epochs=2, batch_size=32, validation_split=0.1)\n",
    "%notify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Our GRU Model\n",
    "\n",
    "Now that we have a benchmark for how an LSTM model performs, let's build the exact same model, but with `GRU()` cells instead of `LSTM()` cells!\n",
    "\n",
    "In the cell below, recreate the network we did above, but with `GRU()` neurons immediately following our Embedding layer instead of `LSTM` cells. Use the exact same parameters as we did above at each layer--we want things to be as equal as possible between them, so that we get a good baseline for comparing the two models on performance and runtime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(20000, 128))\n",
    "gru_model.add(LSTM(50, return_sequences=True))\n",
    "gru_model.add(GlobalMaxPool1D())\n",
    "gru_model.add(Dropout(0.5))\n",
    "gru_model.add(Dense(50, activation='relu'))\n",
    "gru_model.add(Dropout(0.5))\n",
    "gru_model.add(Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compile the model with the same parameters we did for the first network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at a `.summary()` of our GRU model, and see if it has more or less total trainable parameters than our LSTM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 50)          35800     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                1020      \n",
      "=================================================================\n",
      "Total params: 2,599,370\n",
      "Trainable params: 2,599,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train our GRU model using the same parameters as we did for our LSTM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/2\n",
      "10182/10182 [==============================] - 39s 4ms/step - loss: 2.9191 - acc: 0.0814 - val_loss: 2.5047 - val_acc: 0.1811\n",
      "Epoch 2/2\n",
      "10182/10182 [==============================] - 36s 4ms/step - loss: 2.2834 - acc: 0.2435 - val_loss: 1.7994 - val_acc: 0.4302\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"86d52ee1-d58b-46dd-bafc-5d0bdc6fd2c6\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"86d52ee1-d58b-46dd-bafc-5d0bdc6fd2c6\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gru_model.fit(X_t, labels, epochs=2, batch_size=32, validation_split=0.1)\n",
    "%notify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have it! In this particular case, GRUs strongly outperformed LSTMs in the first epoch, but the gap quickly leveled out between them by the end of epoch 2. When comparing LSTMs and GRUs for a given task, this isn't always the case--there are certainly times where LSTMs will outperform GRUs. However, overall, GRUs seem to have a slight advantage over LSTMs. The interesting thing about this is that researchers don't yet know _why_ GRUs tend to slightly outperform LSTMs, especially when GRU cells are a bit simpler than LSTM cells. This is an ongoing area of cutting-edge research in the field of Deep Learning--maybe someday, you'll be the one to solve this mystery!\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lesson, we created and trained comparable LSTM and GRU models for text classification, and compared their performance and runtimes against one another!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
